{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the required libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from skimage import io\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, optimizers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading CSV file containing path of all images with mask label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_df = pd.read_csv('Brain_MRI/data_mask.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1373, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the dataframe containing MRIs which have masks associated with them.\n",
    "brain_df_mask = brain_df[brain_df['mask'] == 1]\n",
    "brain_df_mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "brain_df_mask = brain_df_mask.drop('patient_id', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>mask_path</th>\n",
       "      <th>mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_5.tif</td>\n",
       "      <td>TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_5_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_5.tif</td>\n",
       "      <td>TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_5_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>551</th>\n",
       "      <td>TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_6.tif</td>\n",
       "      <td>TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_6_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>555</th>\n",
       "      <td>TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_6.tif</td>\n",
       "      <td>TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_6_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>617</th>\n",
       "      <td>TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_6.tif</td>\n",
       "      <td>TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_6_...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            image_path  \\\n",
       "445  TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_5.tif   \n",
       "507  TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_5.tif   \n",
       "551  TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_6.tif   \n",
       "555  TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_6.tif   \n",
       "617  TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_6.tif   \n",
       "\n",
       "                                             mask_path  mask  \n",
       "445  TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_5_...     1  \n",
       "507  TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_5_...     1  \n",
       "551  TCGA_CS_4944_20010208/TCGA_CS_4944_20010208_6_...     1  \n",
       "555  TCGA_CS_5393_19990606/TCGA_CS_5393_19990606_6_...     1  \n",
       "617  TCGA_HT_7680_19970202/TCGA_HT_7680_19970202_6_...     1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "brain_df_mask.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Image Datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train, val and test data\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val = train_test_split(brain_df_mask, test_size=0.15)\n",
    "X_test, X_val = train_test_split(X_val, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a image generator\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1./255.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def datagen_func(df):\n",
    "    # original image data generator\n",
    "    image_generator=datagen.flow_from_dataframe(dataframe=df,\n",
    "                                                directory='./Brain_MRI/',\n",
    "                                                x_col=\"image_path\",\n",
    "                                                batch_size= 16,\n",
    "                                                class_mode=None,\n",
    "                                                target_size=(256,256),\n",
    "                                                color_mode='rgb')\n",
    "    # mask data generator\n",
    "    mask_generator=datagen.flow_from_dataframe(dataframe=df,\n",
    "                                               directory='./Brain_MRI/',\n",
    "                                               x_col=\"mask_path\",\n",
    "                                               batch_size=16,\n",
    "                                               class_mode=None,\n",
    "                                               target_size=(256,256),\n",
    "                                               color_mode='grayscale')\n",
    "    \n",
    "    return image_generator, mask_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1167 validated image filenames.\n",
      "Found 1167 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# getting train images\n",
    "timage_generator, tmask_generator = datagen_func(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 validated image filenames.\n",
      "Found 103 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# getting val images\n",
    "vimage_generator, vmask_generator = datagen_func(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 103 validated image filenames.\n",
      "Found 103 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "# getting test images\n",
    "testimage_generator, testmask_generator = datagen_func(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating an iterator of images\n",
    "def data_iterator(image_gen, mask_gen):\n",
    "    for img, mask in zip(image_gen, mask_gen):\n",
    "        yield img, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = data_iterator(timage_generator, tmask_generator)\n",
    "valid_gen = data_iterator(vimage_generator, vmask_generator)\n",
    "test_gen = data_iterator(testimage_generator, testmask_generator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get downsapling convolutional block and skip connection\n",
    "\n",
    "def conv_block(inputs=None, n_filters=32, dropout_prob=0, max_pooling=True):\n",
    "\n",
    "    conv = Conv2D(n_filters,\n",
    "                  3,   \n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(inputs)\n",
    "    \n",
    "    conv = Conv2D(n_filters,\n",
    "                  3,\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    if dropout_prob > 0:\n",
    "        conv = Dropout(dropout_prob)(conv)\n",
    "         \n",
    "    if max_pooling:\n",
    "        next_layer = MaxPooling2D(2,2)(conv)\n",
    "        \n",
    "    else:\n",
    "        next_layer = conv\n",
    "        \n",
    "    skip_connection = conv\n",
    "    \n",
    "    return next_layer, skip_connection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get Convolutional upsampling block\n",
    "    \n",
    "def upsampling_block(expansive_input, contractive_input, n_filters=32):\n",
    "    \n",
    "    up = Conv2DTranspose(\n",
    "                 n_filters,\n",
    "                 (3,3),\n",
    "                 strides=(2,2),\n",
    "                 padding='same')(expansive_input)\n",
    "    \n",
    "    merge = concatenate([up, contractive_input], axis=3)\n",
    "    \n",
    "    conv = Conv2D(n_filters,\n",
    "                  3,\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(merge)\n",
    "    \n",
    "    conv = Conv2D(n_filters,\n",
    "                  3,\n",
    "                  activation='relu',\n",
    "                  padding='same',\n",
    "                  kernel_initializer='he_normal')(conv)\n",
    "    \n",
    "    return conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet Model\n",
    "\n",
    "def unet_model(input_size=(256, 256, 3), n_filters=32):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # downsampling\n",
    "    cblock1 = conv_block(inputs, n_filters)\n",
    "    cblock2 = conv_block(cblock1[0], 2*n_filters)\n",
    "    cblock3 = conv_block(cblock2[0], 4*n_filters)\n",
    "    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.3)\n",
    "    \n",
    "    # bottle-neck\n",
    "    cblock5 = conv_block(cblock4[0], 16*n_filters, dropout_prob=0.3, max_pooling=False) \n",
    "    \n",
    "    # upsampling\n",
    "    ublock6 = upsampling_block(cblock5[0], cblock4[1],  8*n_filters)\n",
    "    ublock7 = upsampling_block(ublock6, cblock3[1],  4*n_filters)\n",
    "    ublock8 = upsampling_block(ublock7, cblock2[1],  2*n_filters)\n",
    "    ublock9 = upsampling_block(ublock8, cblock1[1],  n_filters)\n",
    "\n",
    "    conv9 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock9)\n",
    "\n",
    "    conv10 = Conv2D(1, 1, padding='same', activation='sigmoid')(conv9)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv10)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unet Model\n",
    "\n",
    "def unet_model(input_size=(256, 256, 3), n_filters=32):\n",
    "    \n",
    "    inputs = Input(input_size)\n",
    "    \n",
    "    # downsampling\n",
    "    cblock1 = conv_block(inputs, n_filters)\n",
    "    cblock2 = conv_block(cblock1[0], 2*n_filters)\n",
    "    cblock3 = conv_block(cblock2[0], 4*n_filters, dropout_prob=0.3)\n",
    "    \n",
    "    # bottle-neck\n",
    "    cblock4 = conv_block(cblock3[0], 8*n_filters, dropout_prob=0.3, max_pooling=False) \n",
    "    \n",
    "    # upsampling\n",
    "    ublock5 = upsampling_block(cblock4[0], cblock3[1],  4*n_filters)\n",
    "    ublock6 = upsampling_block(ublock5, cblock2[1],  2*n_filters)\n",
    "    ublock7 = upsampling_block(ublock6, cblock1[1],  n_filters)\n",
    "\n",
    "    conv8 = Conv2D(n_filters,\n",
    "                 3,\n",
    "                 activation='relu',\n",
    "                 padding='same',\n",
    "                 kernel_initializer='he_normal')(ublock7)\n",
    "\n",
    "    conv9 = Conv2D(1, 1, padding='same', activation='sigmoid')(conv8)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=inputs, outputs=conv9)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = unet_model((256, 256, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 256, 256, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 256, 256, 32) 896         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 256, 256, 32) 9248        conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 128, 128, 32) 0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 128, 128, 64) 18496       max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 128, 128, 64) 36928       conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 64, 64, 64)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 64, 64, 128)  73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 64, 64, 128)  0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 32, 32, 128)  0           dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 32, 32, 256)  295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 32, 32, 256)  590080      conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 32, 32, 256)  0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspo (None, 64, 64, 128)  295040      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 64, 64, 256)  0           conv2d_transpose[0][0]           \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 128)  295040      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 64, 64, 128)  147584      conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 128, 128, 64) 73792       conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 128, 128, 128 0           conv2d_transpose_1[0][0]         \n",
      "                                                                 conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 128, 128, 64) 73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 128, 128, 64) 36928       conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 256, 256, 32) 18464       conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256, 256, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 256, 256, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 256, 256, 32) 9248        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 256, 256, 1)  33          conv2d_14[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 2,149,889\n",
      "Trainable params: 2,149,889\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "unet.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use early stopping to exit training if validation loss is not decreasing even after certain epochs (patience)\n",
    "earlystopping = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "\n",
    "# save the best model with least validation loss\n",
    "checkpointer = ModelCheckpoint(filepath=\"localization_weights.h5\", verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN = timage_generator.n/16\n",
    "STEP_SIZE_VALID = vimage_generator.n/16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "72/72 [==============================] - 62s 846ms/step - loss: 0.1054 - accuracy: 0.9700 - val_loss: 0.0978 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.09783, saving model to localization_weights.h5\n",
      "Epoch 2/100\n",
      "72/72 [==============================] - 47s 644ms/step - loss: 0.1031 - accuracy: 0.9703 - val_loss: 0.0920 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.09783 to 0.09204, saving model to localization_weights.h5\n",
      "Epoch 3/100\n",
      "72/72 [==============================] - 47s 642ms/step - loss: 0.1052 - accuracy: 0.9701 - val_loss: 0.0951 - val_accuracy: 0.9725\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.09204\n",
      "Epoch 4/100\n",
      "72/72 [==============================] - 47s 642ms/step - loss: 0.1030 - accuracy: 0.9699 - val_loss: 0.0940 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.09204\n",
      "Epoch 5/100\n",
      "72/72 [==============================] - 47s 643ms/step - loss: 0.1016 - accuracy: 0.9702 - val_loss: 0.0919 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.09204 to 0.09193, saving model to localization_weights.h5\n",
      "Epoch 6/100\n",
      "72/72 [==============================] - 47s 642ms/step - loss: 0.1018 - accuracy: 0.9704 - val_loss: 0.0921 - val_accuracy: 0.9734\n",
      "\n",
      "Epoch 00006: val_loss did not improve from 0.09193\n",
      "Epoch 7/100\n",
      "72/72 [==============================] - 47s 642ms/step - loss: 0.1030 - accuracy: 0.9697 - val_loss: 0.0938 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.09193\n",
      "Epoch 8/100\n",
      "72/72 [==============================] - 48s 659ms/step - loss: 0.1010 - accuracy: 0.9707 - val_loss: 0.0904 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.09193 to 0.09043, saving model to localization_weights.h5\n",
      "Epoch 9/100\n",
      "72/72 [==============================] - 47s 644ms/step - loss: 0.1012 - accuracy: 0.9705 - val_loss: 0.0908 - val_accuracy: 0.9743\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.09043\n",
      "Epoch 10/100\n",
      "72/72 [==============================] - 47s 644ms/step - loss: 0.1025 - accuracy: 0.9698 - val_loss: 0.0918 - val_accuracy: 0.9742\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.09043\n",
      "Epoch 11/100\n",
      "72/72 [==============================] - 47s 645ms/step - loss: 0.1036 - accuracy: 0.9701 - val_loss: 0.0969 - val_accuracy: 0.9722\n",
      "\n",
      "Epoch 00011: val_loss did not improve from 0.09043\n",
      "Epoch 12/100\n",
      "72/72 [==============================] - 47s 641ms/step - loss: 0.1006 - accuracy: 0.9703 - val_loss: 0.0854 - val_accuracy: 0.9746\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.09043 to 0.08536, saving model to localization_weights.h5\n",
      "Epoch 13/100\n",
      "72/72 [==============================] - 47s 641ms/step - loss: 0.1016 - accuracy: 0.9704 - val_loss: 0.0907 - val_accuracy: 0.9735\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.08536\n",
      "Epoch 14/100\n",
      "72/72 [==============================] - 47s 643ms/step - loss: 0.1019 - accuracy: 0.9699 - val_loss: 0.0894 - val_accuracy: 0.9732\n",
      "\n",
      "Epoch 00014: val_loss did not improve from 0.08536\n",
      "Epoch 15/100\n",
      "72/72 [==============================] - 47s 641ms/step - loss: 0.0991 - accuracy: 0.9705 - val_loss: 0.0919 - val_accuracy: 0.9733\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.08536\n",
      "Epoch 16/100\n",
      "72/72 [==============================] - 47s 644ms/step - loss: 0.0999 - accuracy: 0.9702 - val_loss: 0.0914 - val_accuracy: 0.9730\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.08536\n",
      "Epoch 17/100\n",
      "72/72 [==============================] - 47s 641ms/step - loss: 0.1013 - accuracy: 0.9698 - val_loss: 0.0897 - val_accuracy: 0.9739\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.08536\n",
      "Epoch 00017: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = unet.fit(train_gen,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    batch_size=16,\n",
    "                    epochs=100,\n",
    "                    callbacks=[checkpointer, earlystopping],\n",
    "                    validation_data=valid_gen,\n",
    "                    validation_steps=STEP_SIZE_VALID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model architecture to json file for future use\n",
    "\n",
    "model_json = unet.to_json()\n",
    "with open(\"localization_model.json\",\"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 190ms/step - loss: 0.0966 - accuracy: 0.9716\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.09659004211425781, 0.9716346263885498]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unet.evaluate(test_gen, steps=testimage_generator.n/16, verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
